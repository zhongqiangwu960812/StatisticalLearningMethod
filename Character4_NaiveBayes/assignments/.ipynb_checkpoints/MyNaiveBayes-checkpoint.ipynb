{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自编程实现朴素贝叶斯算法\n",
    "> 问题描述：取λ=0.2. 由下表训练数据， 利用先验概率的贝叶斯估计确定X=(2, S)的类标记y。 表中x^(1), x^(2)为特征， 取值的集合分别为A1={1,2,3}\n",
    "A2={S,M,L} Y为类标签 属于{1,-1}\n",
    ">>| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | \n",
    ":-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: \n",
    "x^(1) | 1 | 1 | 1 | 1 | 1 | 2 | 2 | 2 | 2 | 2 | 3 | 3 | 3 | 3 | 3 |\n",
    "x^(2) | S | M | M | S | S | S | M | M | L | L | L | M | M | L | L |\n",
    "Y | -1 | -1 | 1 | 1 | -1 | -1 | -1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | -1 |\n",
    "\n",
    ">下面自编程实现朴素贝叶斯算法， 伪代码如下：\n",
    ">> 1. 构造训练集<br> \n",
    "2. 构造测试集 <br>\n",
    "3. 创建朴素贝叶斯模型并训练 <br> \n",
    "    (1) 计算条件概率和Y的先验概率<br>\n",
    "    (2) 计算联合概率，根据最大化联合概率返回结果\n",
    "4. 测试模型，得到分类标签\n",
    "> \n",
    "PS： 当贝叶斯估计λ=0时， 就是极大似然估计\n",
    ">\n",
    "> 学习Python： pandas的DataFrame结构， Python的函数 .unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. 定义朴素贝叶斯模型\n",
    "> 梳理一下思路：\n",
    ">> 1. 初始化成员变量<br>\n",
    "2. 定义fit函数计算先验概率和条件概率<br>\n",
    "3. 定义predict函数计算联合概率，并根据联合概率最大化返回分类标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    # 初始化成员变量\n",
    "    def __init__(self, lamda=0):\n",
    "        self.lamda = lamda      # 贝叶斯系数， 取0时，为极大似然估计\n",
    "        self.y_types = None    #  y的类型\n",
    "        self.y_types_count = None   # y的类型数量\n",
    "        self.y_types_proba = None   # y的类型概率\n",
    "        self.x_types_proba = dict()  #  这是一个字典，求条件概率的时候用，给定y的类型， 第几个特征取什么值，格式： （xi的编号，xi的取值，y的类型）\n",
    "        \n",
    "    # 定义训练函数\n",
    "    def fit(self, X_train, Y_train):\n",
    "        X_new_train = pd.DataFrame(X_train)     # 转换成pandas DataFrame数据格式\n",
    "        Y_new_train = pd.DataFrame(Y_train)\n",
    "        print(\"*************************************\")            # 为了debug方便，可以注释\n",
    "        print(\"转换完结构：\")\n",
    "        print(\"X_new_train=\")\n",
    "        print(X_new_train)\n",
    "        print(\"Y_new_train=\")\n",
    "        print(Y_new_train)\n",
    "        print(\"*************************************\")\n",
    "        \n",
    "        # y的类型数量统计   pandas 的value_counts()函数可以对Series里面的每个值进行计数并且排序。\n",
    "        self.y_types = np.unique(Y_train)   # y的所有取值类型\n",
    "        self.y_types_count = Y_new_train[0].value_counts()         # value_counts()返回的结果是一个Series数组\n",
    "        # 这里还要注意一下，这个value_counts是针对于某一列，不能用整个DateFrame\n",
    "\n",
    "        # y的类型概率统计\n",
    "        self.y_types_proba = (self.y_types_count+self.lamda) / (Y_new_train.shape[0]+len(self.y_types)*self.lamda) \n",
    "        \n",
    "        # 计算条件概率  （xi 的编号,xi的取值，y的类型）：概率的计算\n",
    "        for idx in X_new_train.columns:     # 变量X_new_train的所有列（即特征x^(1), x^(2)...x^(n)）\n",
    "            for j in self.y_types:         # 选取每一个y的类型\n",
    "                p_x_y = X_new_train[(Y_new_train==j).values][idx].value_counts() #选择所有y==j为真的数据点的第idx个特征的值，并对这些值进行（类型：数量）统计\n",
    "                for i in p_x_y.index: #计算（xi 的编号,xi的取值，y的类型）：概率\n",
    "                    self.x_types_proba[(idx,i,j)]=(p_x_y[i]+self.lamda)/(self.y_types_count[j]+p_x_y.shape[0]*self.lamda)\n",
    "        \n",
    "        print(\"*************************************\")\n",
    "        print(\"计算先验概率时的一些数据测试\")\n",
    "        print(\"y_types_count=\\n{}\\n\".format(self.y_types_count))\n",
    "        print(\"y_types_proba=\\n{}\\n\".format(self.y_types_proba))\n",
    "        print(\"选择X_new_train中，对应的Y_new_train=-1的行组成新表格，然后数量统计0列\\n\", X_new_train[(Y_new_train==-1).values][0].value_counts())\n",
    "        print(\"看看那个字典的最后表示：\\nx_types_proba=\")\n",
    "        print(self.x_types_proba)\n",
    "        print(\"*************************************\") \n",
    "        \n",
    "    # 计算联合概率，并预测\n",
    "    def predict(self,X_new):\n",
    "        res=[]         # 存放结果\n",
    "        for y in self.y_types: #遍历y的可能取值\n",
    "            p_y=self.y_types_proba[y]  #计算y的先验概率P(Y=ck)\n",
    "            p_xy=1\n",
    "            for idx,x in enumerate(X_new):\n",
    "                p_xy*=self.x_types_proba[(idx,x,y)] #计算P(X=(x1,x2...xd)/Y=ck)\n",
    "            res.append(p_y*p_xy)\n",
    "        for i in range(len(self.y_types)):\n",
    "            print(\"[{}]对应概率：{:.2%}\".format(self.y_types[i],res[i]))\n",
    "        #返回最大后验概率对应的y值\n",
    "        return self.y_types[np.argmax(res)]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. 主函数\n",
    "> 1. 构造训练集<br>\n",
    "2. 构造测试集 <br>\n",
    "3. 创建朴素贝叶斯模型并训练 <br>\n",
    "4. 测试模型，返回分类标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # 构造训练集\n",
    "    X_train = np.array([\n",
    "                        [1, \"S\"], \n",
    "                        [1, \"M\"],\n",
    "                        [1, \"M\"],\n",
    "                        [1, \"S\"],\n",
    "                        [1, \"S\"],\n",
    "                        [2, \"S\"],\n",
    "                        [2, \"M\"],\n",
    "                        [2, \"M\"],\n",
    "                        [2, \"L\"], \n",
    "                        [2, \"L\"],\n",
    "                        [3, \"L\"], \n",
    "                        [3, \"M\"],\n",
    "                        [3, \"M\"],\n",
    "                        [3, \"L\"],\n",
    "                        [3, \"L\"]\n",
    "                        ])\n",
    "    Y_train = np.array([-1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1])\n",
    "    #print(\"X_train.shape={},   Y_train.shape={}\".format(X_train.shape, Y_train.shape))   # X_train(15, 2), Y_train(15,)\n",
    "    \n",
    "    # 构造测试集\n",
    "    X_test = np.array([2, \"S\"])\n",
    "    #print(\"X_test.shape={}\".format(X_test.shape))    #  X_test(2,)\n",
    "    \n",
    "    # 创建贝叶斯模型并训练\n",
    "    clf = NaiveBayes(lamda=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    # 测试模型\n",
    "    y_predict = clf.predict(X_test)\n",
    "    print(\"*************************************\")\n",
    "    print(\"最终结果：\")\n",
    "    print(\"{}被分类为： {}\".format(X_test, y_predict))\n",
    "    print(\"*************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "转换完结构：\n",
      "X_new_train=\n",
      "    0  1\n",
      "0   1  S\n",
      "1   1  M\n",
      "2   1  M\n",
      "3   1  S\n",
      "4   1  S\n",
      "5   2  S\n",
      "6   2  M\n",
      "7   2  M\n",
      "8   2  L\n",
      "9   2  L\n",
      "10  3  L\n",
      "11  3  M\n",
      "12  3  M\n",
      "13  3  L\n",
      "14  3  L\n",
      "Y_new_train=\n",
      "    0\n",
      "0  -1\n",
      "1  -1\n",
      "2   1\n",
      "3   1\n",
      "4  -1\n",
      "5  -1\n",
      "6  -1\n",
      "7   1\n",
      "8   1\n",
      "9   1\n",
      "10  1\n",
      "11  1\n",
      "12  1\n",
      "13  1\n",
      "14 -1\n",
      "*************************************\n",
      "*************************************\n",
      "计算先验概率时的一些数据测试\n",
      "y_types_count=\n",
      " 1    9\n",
      "-1    6\n",
      "Name: 0, dtype: int64\n",
      "\n",
      "y_types_proba=\n",
      " 1    0.6\n",
      "-1    0.4\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "选择X_new_train中，对应的Y_new_train=-1的行组成新表格，然后数量统计0列\n",
      " 1    3\n",
      "2    2\n",
      "3    1\n",
      "Name: 0, dtype: int64\n",
      "看看那个字典的最后表示：\n",
      "x_types_proba=\n",
      "{(0, '1', -1): 0.5, (0, '2', -1): 0.33333333333333331, (0, '3', -1): 0.16666666666666666, (0, '3', 1): 0.44444444444444442, (0, '2', 1): 0.33333333333333331, (0, '1', 1): 0.22222222222222221, (1, 'S', -1): 0.5, (1, 'M', -1): 0.33333333333333331, (1, 'L', -1): 0.16666666666666666, (1, 'L', 1): 0.44444444444444442, (1, 'M', 1): 0.44444444444444442, (1, 'S', 1): 0.1111111111111111}\n",
      "*************************************\n",
      "[-1]对应概率：6.67%\n",
      "[1]对应概率：2.22%\n",
      "*************************************\n",
      "最终结果：\n",
      "['2' 'S']被分类为： -1\n",
      "*************************************\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. 回顾总结\n",
    "> 朴素贝叶斯分类的思想一定要清楚， 假设分类标签Y事先服从一定的概率分布，也就是先验分布，然后根据训练集，求出在给定Y的条件下X的概率，这样，根据贝叶斯公式，就可以求出，给定X的条件下Y的概率分布，最大化这一个就是结果。\n",
    "> 思想比较简单，但是Python真正的实现起来，还是挺复杂，涉及到一些不太懂的存储和操作，比如pandas，之前只是粗略的学习过，不会用， np.unique还有有关pandas的一些操作， 在这里要重新回顾整理一下重要的：\n",
    ">> 1. pandas 的一些操作和定义<br>\n",
    "2. numpy的一些函数操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 pandas 数据类型的定义和一些操作\n",
    ">pandas是在numpy的基础上建立的新的程序库， 和numpy最大的不同是用来处理表格型或者异质性数据， 而Numpy主要处理同质性的数值类数组数据。\n",
    ">\n",
    "> 两大常用的数据结构： Series和DataFrame\n",
    ">> Series可以理解为带索引的一维数组对象，包含了一个值序列和一个索引序列<br>\n",
    "DataFrame类似于Numpy中的二维数组， 但是有行列标签， 并且方法更加灵活"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Series\n",
    "> 创建的三种方式：\n",
    ">>1. 创建可以通过一维数组创建 <br>\n",
    "2. 字典的方式创建  <br>\n",
    "3. DataFram的某一行或者某一列创建<br》\n",
    ">\n",
    "> 对象的两个属性： \n",
    ">>1. index(索引）<br> \n",
    "2. values(值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[1 2 3 4]\n",
      "[1 2 3 4]\n",
      "RangeIndex(start=0, stop=4, step=1)\n",
      "Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "2\n",
      "d     True\n",
      "c     True\n",
      "b    False\n",
      "a     True\n",
      "dtype: bool\n",
      "d     8\n",
      "c    14\n",
      "b   -10\n",
      "a     6\n",
      "dtype: int64\n",
      "Ohio      35000\n",
      "Oregon    16000\n",
      "Texas     71000\n",
      "Utah       5000\n",
      "dtype: int64\n",
      "California        NaN\n",
      "Ohio          35000.0\n",
      "Oregon        16000.0\n",
      "Texas         71000.0\n",
      "dtype: float64\n",
      "California     True\n",
      "Ohio          False\n",
      "Oregon        False\n",
      "Texas         False\n",
      "dtype: bool California     True\n",
      "Ohio          False\n",
      "Oregon        False\n",
      "Texas         False\n",
      "dtype: bool\n",
      "state\n",
      "California        NaN\n",
      "Ohio          35000.0\n",
      "Oregon        16000.0\n",
      "Texas         71000.0\n",
      "Name: Population, dtype: float64\n",
      "\n",
      "自动对齐:\n",
      "s1序列：\n",
      "  a    10\n",
      "b    15\n",
      "c    20\n",
      "d    30\n",
      "e    55\n",
      "f    80\n",
      "dtype: int32\n",
      "s2序列：\n",
      "  a    12\n",
      "c    11\n",
      "g    13\n",
      "b    16\n",
      "d    14\n",
      "f    16\n",
      "dtype: int32\n",
      "a    22.0\n",
      "b    31.0\n",
      "c    31.0\n",
      "d    44.0\n",
      "e     NaN\n",
      "f    96.0\n",
      "g     NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Series创建和使用 \n",
    "a = [1, 2, 3, 4]    #  这是一个列表  \n",
    "print(a)       # [1, 2, 3, 4]\n",
    "b = np.array([1, 2, 3, 4])        # 这是一个一维数组  \n",
    "print(b)        # [1 2 3 4]\n",
    "\n",
    "## 通过列表或者数组创建序列\n",
    "obj = pd.Series(b)   # 其实列表和一维数组都可以放到这里的\n",
    "print(obj.values)    # 这是一个一维数组  [1 2 3 4]\n",
    "print(obj.index)    # RangeIndex(start=0, stop=4, step=1)\n",
    "\n",
    "# 为上面的obj创建索引，通过索引标签来引用值\n",
    "obj.index = ['a', 'b', 'c', 'd']       # 直接加\n",
    "print(obj.index)       # Index(['a', 'b', 'c', 'd'], dtype='object')\n",
    "print(obj['b'])          # 有了索引之后，可以通过索引来引用值了\n",
    "#print(obj)\n",
    "obj2 = pd.Series([4, 7, -5, 3], index=['d', 'c', 'b', 'a'])     # 在创建对象的时候，可以直接指明索引\n",
    "print(obj2>2)       # 可以直接用bool值过滤，或者标量相乘\n",
    "print(obj2 * 2)\n",
    "\n",
    "## 通过字典创建序列\n",
    "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
    "obj3 = pd.Series(sdata)\n",
    "print(obj3)      #  产生的Series的索引将是排好序的字典键\n",
    "# 你可以将字典键按照你所要的顺序传递给构造函数\n",
    "stats = ['California', 'Ohio', 'Oregon', 'Texas']\n",
    "obj4 = pd.Series(sdata, index=stats)\n",
    "print(obj4)   #  这时候按照你给的字典键的顺序输出，不过由于没有Cailfornia，所以输出NaN  表示缺失数据\n",
    "print(obj4.isnull(), pd.isnull(obj4))\n",
    "# Series对象自身和索引都有name属性  \n",
    "obj4.name = 'Population'\n",
    "obj4.index.name = 'state'\n",
    "#obj4.values.name = 'area'    #  值没有name属性\n",
    "print(obj4)\n",
    "\n",
    "## 自动对齐  类似于数据库中的join\n",
    "print(\"\\n自动对齐:\")\n",
    "s1 = pd.Series(np.array([10, 15, 20, 30, 55, 80]), index=['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "s2 = pd.Series(np.array([12, 11, 13, 16, 14, 16]), index=['a', 'c', 'g', 'b', 'd', 'f'])\n",
    "print('s1序列：\\n ',  s1)\n",
    "print('s2序列：\\n ', s2)\n",
    "print(s1+s2)   #s1中不存在g索引，s2中不存在e索引，所以数据运算会产生缺失值NaN。 这里的算术运算自动实现了对齐，对于数据的对齐，不仅是行索引的自动对齐，同时也会对列索引自动对齐，数据框相当于二维数组的推广"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 DataFrame数据\n",
    "> 创建的三种方式：\n",
    ">> 1. 通过二维数组创建<br>\n",
    "2. 通过字典的方式创建<br>\n",
    "3. 通过数据框创建\n",
    "\n",
    "> 两种索引：\n",
    ">> 1. columns(列索引）<br>\n",
    "2. index(行索引）\n",
    ">\n",
    "> 属性值： values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pop   state  year\n",
      "0  1.5    Ohio  2000\n",
      "1  1.7    Ohio  2001\n",
      "2  3.6    Ohio  2002\n",
      "3  2.4  Nevada  2001\n",
      "4  2.9  Nevada  2002\n",
      "   year   state  pop\n",
      "0  2000    Ohio  1.5\n",
      "1  2001    Ohio  1.7\n",
      "2  2002    Ohio  3.6\n",
      "3  2001  Nevada  2.4\n",
      "4  2002  Nevada  2.9\n",
      "5  2003  Nevada  3.2\n",
      "       year   state  pop debt\n",
      "one    2000    Ohio  1.5  NaN\n",
      "two    2001    Ohio  1.7  NaN\n",
      "three  2002    Ohio  3.6  NaN\n",
      "four   2001  Nevada  2.4  NaN\n",
      "five   2002  Nevada  2.9  NaN\n",
      "six    2003  Nevada  3.2  NaN\n",
      "one        Ohio\n",
      "two        Ohio\n",
      "three      Ohio\n",
      "four     Nevada\n",
      "five     Nevada\n",
      "six      Nevada\n",
      "Name: state, dtype: object\n",
      "year     2002\n",
      "state    Ohio\n",
      "pop       3.6\n",
      "debt      NaN\n",
      "Name: three, dtype: object\n",
      "       year   state  pop  debt\n",
      "one    2000    Ohio  1.5   0.0\n",
      "two    2001    Ohio  1.7   1.0\n",
      "three  2002    Ohio  3.6   2.0\n",
      "four   2001  Nevada  2.4   3.0\n",
      "five   2002  Nevada  2.9   4.0\n",
      "six    2003  Nevada  3.2   5.0\n",
      "       year   state  pop  debt  eastern\n",
      "one    2000    Ohio  1.5   0.0     True\n",
      "two    2001    Ohio  1.7   1.0     True\n",
      "three  2002    Ohio  3.6   2.0     True\n",
      "four   2001  Nevada  2.4   3.0    False\n",
      "five   2002  Nevada  2.9   4.0    False\n",
      "six    2003  Nevada  3.2   5.0    False\n",
      "Index(['year', 'state', 'pop', 'debt', 'eastern'], dtype='object')\n",
      "Index(['pop', 'state', 'year'], dtype='object')\n",
      "       year   state  pop  debt\n",
      "one    2000    Ohio  1.5   0.0\n",
      "two    2001    Ohio  1.7   1.0\n",
      "three  2002    Ohio  3.6   2.0\n",
      "four   2001  Nevada  2.4   3.0\n",
      "five   2002  Nevada  2.9   4.0\n",
      "six    2003  Nevada  3.2   5.0\n",
      "      Nevada  Ohio\n",
      "2000     NaN   1.5\n",
      "2001     2.4   1.7\n",
      "2002     2.9   3.6\n",
      "        2000  2001  2002\n",
      "Nevada   NaN   2.4   2.9\n",
      "Ohio     1.5   1.7   3.6\n",
      "state  Nevada  Ohio\n",
      "year               \n",
      "2000      NaN   1.5\n",
      "2001      2.4   1.7\n",
      "2002      2.9   3.6\n",
      "[[ nan  1.5]\n",
      " [ 2.4  1.7]\n",
      " [ 2.9  3.6]]\n"
     ]
    }
   ],
   "source": [
    "## 最常用的创建方式利用包含等长度的列表或Numpy数组的字典形式\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'], \n",
    "        'year': [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]\n",
    "       }\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame.head())     # head方法只会显示前5行   默认这个列的顺序是字典序 pop state year\n",
    "# 还可以自己指定列的顺序\n",
    "frame1 = pd.DataFrame(data, columns=['year', 'state', 'pop']) \n",
    "print(frame1)\n",
    "#  如果传的列不包含在字典中，就用NaN表示\n",
    "frame2 = pd.DataFrame(data, columns=['year', 'state', 'pop', 'debt'], index=['one', 'two', 'three', 'four', 'five', 'six'])\n",
    "print(frame2)\n",
    "# DataFrame中的一列，可以按字典标记或属性那样检索为Series\n",
    "print(frame2['state'])\n",
    "# 行也可以通过位置或者特殊属性进行选取\n",
    "print(frame2.loc['three'])\n",
    "# 列的引用是可以修改的\n",
    "frame2['debt'] = np.arange(6.)    # arange类似于Python中的range， 但是range只能生成int型，而arange可以float型\n",
    "print(frame2)\n",
    "# 在frame2中增加一列\n",
    "frame2['eastern'] = frame2.state == 'Ohio'   # frame2.state与frame2['state'] 的区别： 后者对于任意列名都有效，前者只在列名是有效的Python变量名时有效\n",
    "print(frame2)\n",
    "print(frame2.columns)   # Index(['year', 'state', 'pop', 'debt', 'eastern'], dtype='object')\n",
    "# 删除一列 del\n",
    "del frame2['eastern']\n",
    "print(frame.columns)  # Index(['pop', 'state', 'year'], dtype='object')  注意，从DataFrame选取的列行等都是视图不是拷贝，修改直接等于修改原表\n",
    "print(frame2)\n",
    "\n",
    "## 另一种常用的数据形式是包含字典的嵌套字典\n",
    "pop = {'Nevada': {2001: 2.4, 2002: 2.9}, 'Ohio':{2000:1.5, 2001: 1.7, 2002: 3.6}}\n",
    "frame3 = pd.DataFrame(pop)    # 当然也可以自己指定索引  pd.DataFrame(pop, index=[2001, 2002, 2003])  这时候2003这块会有缺省值\n",
    "print(frame3)\n",
    "# 使用Numpy语法进行转置\n",
    "print(frame3.T)\n",
    "# 这里的索引和列都会有name属性\n",
    "frame3.index.name = 'year'\n",
    "frame3.columns.name = 'state'\n",
    "print(frame3)\n",
    "# DataFrame的values属性会以ndarry数组的形式返回\n",
    "print(frame3.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关于pandas的对象和创建先说到这， 因为pandas的知识体系太过于庞大， 后面还有具体的操作和功能，像数据的增删改查， 统计分析，缺失值处理等， 具体的见我的笔记。\n",
    "\n",
    "http://note.youdao.com/noteshare?id=28264a6b8536e4448e0bf3de701cd230&sub=25080C078C444E6E8B0C809C88BD0C76"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
